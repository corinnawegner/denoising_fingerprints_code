{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we try to implement a SVC to classify between the real and simulated data. Then we improve the performance of the model step-by-step by doing GridSearch and optimizing the parameters around the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and splitting  them into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1102)\n",
      "(1507, 1102)\n",
      "(3007, 1102)\n",
      "(2405, 1102)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "z = np.zeros((1500,1), dtype=int)\n",
    "o = np.ones((1507, 1), dtype=int)\n",
    "\n",
    "gen = np.loadtxt(\"qcs_gen.txt\", delimiter=\",\")\n",
    "gen = np.concatenate((gen, z), axis=1)\n",
    "print(gen.shape)\n",
    "\n",
    "real = np.loadtxt(\"qcs_real.txt\", delimiter=\",\")\n",
    "real = np.concatenate((real, o), axis=1)\n",
    "print(real.shape)\n",
    "\n",
    "data = np.concatenate((gen, real), axis=0)\n",
    "print(data.shape)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True, stratify=None)\n",
    "print(train.shape)\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42, shuffle=True, stratify=None)\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the SVC without optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = train[:, :-1]\n",
    "y = train[:, -1]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the performance of the SVC using accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8837209302325582"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(test[:, :-1])\n",
    "y_true = test[:, -1]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to increase the performance of the model by optimizing the parameters with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('svc',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'svc__C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'svc__kernel': ('linear', 'rbf', 'poly', 'sigmoid')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'svc__kernel':('linear', 'rbf', 'poly', 'sigmoid'), \"svc__C\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "pipeline = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf = GridSearchCV(estimator=pipeline, param_grid=parameters)\n",
    "clf.fit(train[:, :-1], train[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the accuracy has increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518272425249169"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(test[:, :-1])\n",
    "y_true = test[:, -1]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 'warn',\n",
       " 'error_score': 'raise-deprecating',\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "       max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "       tol=0.001, verbose=False))],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'estimator__svc': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'estimator__standardscaler__copy': True,\n",
       " 'estimator__standardscaler__with_mean': True,\n",
       " 'estimator__standardscaler__with_std': True,\n",
       " 'estimator__svc__C': 1.0,\n",
       " 'estimator__svc__cache_size': 200,\n",
       " 'estimator__svc__class_weight': None,\n",
       " 'estimator__svc__coef0': 0.0,\n",
       " 'estimator__svc__decision_function_shape': 'ovr',\n",
       " 'estimator__svc__degree': 3,\n",
       " 'estimator__svc__gamma': 'auto',\n",
       " 'estimator__svc__kernel': 'rbf',\n",
       " 'estimator__svc__max_iter': -1,\n",
       " 'estimator__svc__probability': False,\n",
       " 'estimator__svc__random_state': None,\n",
       " 'estimator__svc__shrinking': True,\n",
       " 'estimator__svc__tol': 0.001,\n",
       " 'estimator__svc__verbose': False,\n",
       " 'estimator': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('svc',\n",
       "                  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                      kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=None, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'iid': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'svc__kernel': ('linear', 'rbf', 'poly', 'sigmoid'),\n",
       "  'svc__C': [0.001, 0.01, 0.1, 1, 10]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already been able to increase the accuracy from 88 to 95 percent using GridSearch. Now we try to improve the performance even more. Above we can see the \"optimal\" values. Using the determined best kernel \"rbf\", we do grid search again, around the \"optimal\" value for C, 1.0 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9401993355481728"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\"svc__C\": [0.1,0.5,0.7, 1,1.2,1.5,2, 2.5, 3, 3.5, 4,5,7]}\n",
    "pipeline = make_pipeline(StandardScaler(), SVC(kernel='rbf', gamma='auto'))\n",
    "clf = GridSearchCV(estimator=pipeline, param_grid=parameters)\n",
    "clf.fit(train[:, :-1], train[:, -1])\n",
    "y_pred = clf.predict(test[:, :-1])\n",
    "y_true = test[:, -1]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 'warn',\n",
       " 'error_score': 'raise-deprecating',\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "       max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "       tol=0.001, verbose=False))],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'estimator__svc': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'estimator__standardscaler__copy': True,\n",
       " 'estimator__standardscaler__with_mean': True,\n",
       " 'estimator__standardscaler__with_std': True,\n",
       " 'estimator__svc__C': 1.0,\n",
       " 'estimator__svc__cache_size': 200,\n",
       " 'estimator__svc__class_weight': None,\n",
       " 'estimator__svc__coef0': 0.0,\n",
       " 'estimator__svc__decision_function_shape': 'ovr',\n",
       " 'estimator__svc__degree': 3,\n",
       " 'estimator__svc__gamma': 'auto',\n",
       " 'estimator__svc__kernel': 'rbf',\n",
       " 'estimator__svc__max_iter': -1,\n",
       " 'estimator__svc__probability': False,\n",
       " 'estimator__svc__random_state': None,\n",
       " 'estimator__svc__shrinking': True,\n",
       " 'estimator__svc__tol': 0.001,\n",
       " 'estimator__svc__verbose': False,\n",
       " 'estimator': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('svc',\n",
       "                  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                      decision_function_shape='ovr', degree=3, gamma='auto',\n",
       "                      kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=None, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'iid': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'svc__C': [0.1,\n",
       "   0.5,\n",
       "   0.7,\n",
       "   1,\n",
       "   1.2,\n",
       "   1.5,\n",
       "   2,\n",
       "   2.5,\n",
       "   3,\n",
       "   3.5,\n",
       "   4,\n",
       "   5,\n",
       "   7]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "x_data = test[:, :-1]\n",
    "\n",
    "#standard scaling the data\n",
    "standardscaler = StandardScaler()\n",
    "x_data = standardscaler.fit_transform(x_data)\n",
    "\n",
    "###---##---###  Nested CV & AUC\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Nested CV with parameter optimization\n",
    "clf = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=inner_cv, scoring='roc_auc')\n",
    "\n",
    "# Making predictions\n",
    "predictions_autoencoder = cross_val_predict(clf, X = x_data, y = test[:, -1], cv\n",
    "= outer_cv, method = 'predict_proba', n_jobs = -1)\n",
    "\n",
    "#everything for the standard method\n",
    "svm = SVC(kernel=\"rbf\", probability=True)\n",
    "pipeline = Pipeline([('svm', svm)])\n",
    "clf_std = GridSearchCV(estimator=pipeline, param_grid=p_grid, cv=inner_cv, scoring='roc_auc')\n",
    "predictions_std = cross_val_predict(clf_std, X = x_data_std, y = y_data, cv\n",
    "= outer_cv, method = 'predict_proba', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only positive probabilities\n",
    "#predictions_autoencoder = predictions_autoencoder[:,1]\n",
    "predictions_nopreprocessing = predictions_nopreprocessing[:,1]\n",
    "predictions_std = predictions_std[:,1]\n",
    "\n",
    "#calculating the ROC curves\n",
    "fpr_autoencoder, tpr_autoencoder, _ = metrics.roc_curve(y_data, predictions_autoencoder)\n",
    "fpr_nopreprocessing, tpr_nopreprocessing, _ = metrics.roc_curve(y_data, predictions_nopreprocessing)\n",
    "fpr_std, tpr_std, _ = metrics.roc_curve(y_data, predictions_std)\n",
    "\n",
    "#calculating the AUC's\n",
    "auc_autoencoder = metrics.auc(fpr_autoencoder, tpr_autoencoder)\n",
    "auc_nopreprocessing = metrics.auc(fpr_nopreprocessing, tpr_nopreprocessing)\n",
    "auc_std = metrics.auc(fpr_std, tpr_std)\n",
    "\n",
    "#sklearn.metrics.roc_curve(y_true, y_score, *, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "\n",
    "#fpr_autoencoder, tpr_autoencoder, _ =\n",
    "roc_autoencoder = RocCurveDisplay(fpr = fpr_autoencoder, \n",
    "                                  tpr = tpr_autoencoder, \n",
    "                                  roc_auc= auc_autoencoder, \n",
    "                                  estimator_name=\"autoencoder\")\n",
    "\n",
    "roc_autoencoder.plot(color=\"red\", ax=ax)\n",
    "\n",
    "roc_std = RocCurveDisplay(fpr = fpr_std,\n",
    "                          tpr = tpr_std,\n",
    "                          roc_auc = auc_std, \n",
    "                          estimator_name=\"standard preprocessing method\")\n",
    "\n",
    "roc_std.plot(color=\"darkorange\", ax=ax)\n",
    "\n",
    "roc_nopreprocessing = RocCurveDisplay(fpr = fpr_nopreprocessing,\n",
    "                                      tpr = tpr_nopreprocessing, \n",
    "                                      roc_auc= auc_nopreprocessing, \n",
    "                                      estimator_name=\"no preprocessing\")\n",
    "\n",
    "roc_nopreprocessing.plot(color=\"darkblue\", ax=ax)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristics\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
